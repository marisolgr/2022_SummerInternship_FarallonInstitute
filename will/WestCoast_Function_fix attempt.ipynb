{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2022c3-5df1-4df9-90b5-caf2689a46fd",
   "metadata": {},
   "source": [
    "# westcoast Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ea3a5e-1913-42d7-a81d-63bd5ba7a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from datetime import date\n",
    "import warnings \n",
    "\n",
    "#from 2022_SummerInternship_FarallonInstitute.paul.Identify upwelling events (part 1) import compile_function\n",
    "\n",
    "#Warnings\n",
    "warnings.simplefilter('ignore') \n",
    "\n",
    "#load map packages\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from calendar import month_abbr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7a3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# great start will!\n",
    "# let's get this function to the next level\n",
    "#   -  instead of only looking into one file, let's search all the data files that have dataa in the west coast\n",
    "#   -  for that, use hard coded relative directory (../saildrone_data), and use glob to get all the file names\n",
    "#   -  open each, filter, and compile all into a single dataset (check meg's function or ask meg)\n",
    "#   -  make a final map plot of all the data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa319cc-c6b9-4366-a0e7-fb43bc708ccb",
   "metadata": {},
   "source": [
    "## Compile_Datasets Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef60095-8ccc-4cae-90db-430994ab9477",
   "metadata": {},
   "source": [
    "#### Compile_Datasets is used in westcoast to aggregate all cruise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b7773e-f1f0-4b77-bc72-b3cc407ddfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Paul\n",
    "#compiles all voyages\n",
    "def Compile_Datasets(fn_list_in):\n",
    "\n",
    "\n",
    "    # fn_list_in: list of strings with the file names, or filename(string), or \"all\"\n",
    "    # returns: compiled list\n",
    "    fn_list = []\n",
    "    \n",
    "    ddir = \"../saildrone_data\"\n",
    "    \n",
    "    # Make sure the fn_list_in is formatted correctly\n",
    "    if(fn_list_in == \"all\"):\n",
    "        \n",
    "        fn_list = glob.glob(ddir+ '/*.nc')\n",
    "    elif(type(fn_list_in) == 'list' and type(fn_list_in[0]) == 'string'):\n",
    "        fn_list = fn_list_in\n",
    "    elif(type(fn_list_in) == 'string'):\n",
    "        fn_list[0] = fn_list_in\n",
    "    else: \n",
    "        raise Exception(\"first argument to 'Compile_Data_Set_And_Graph' function must be; a list of file names, a file name, or \\\"all\\\"\")\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    # open the first dataset\n",
    "    sail = xr.open_dataset(fn_list[0])\n",
    "    \n",
    "    sail = sail.drop_vars(\"trajectory\", errors='ignore')\n",
    "    \n",
    "    # give the first dataset a relative ID so all datasets can be differentiated\n",
    "    sail[\"relativeID\"] = 0\n",
    "    # make lists for certain variables that remain constant for each dataset. these are used later in the last two cells\n",
    "    yearList = [sail[\"time\"][0].dt.year]\n",
    "    durationList = [sail[\"time\"][len(sail[\"time\"]) - 1] - sail[\"time\"][0]]\n",
    "    # take the actual cruise ID from the dataset attributes and put it in a new list\n",
    "    try:\n",
    "        realID = [int(sail.attrs[\"id\"])]\n",
    "    except:\n",
    "        realID = [fn_list[0]]\n",
    "    sail[\"realID\"] = realID[0]\n",
    "    # add the duration back to the dataset\n",
    "    sail[\"duration\"] = durationList[0]\n",
    "\n",
    "    # repeat previous steps for other datasets that need to be combined.\n",
    "\n",
    "    if len(fn_list) > 1:\n",
    "        for i in range(1, len(fn_list)):\n",
    "            temp = xr.open_dataset(fn_list[i])\n",
    "            temp = temp.drop_vars(\"trajectory\", errors='ignore')\n",
    "            temp[\"relativeID\"] = i\n",
    "            yearList.append(temp[\"time\"][0].dt.year)\n",
    "            \n",
    "            try:\n",
    "                realID.append(int(temp.attrs[\"id\"]))\n",
    "            except:\n",
    "                realID.append(fn_list[i])\n",
    "                \n",
    "            tempDuration = temp[\"time\"][len(temp[\"time\"]) - 1] - temp[\"time\"][0]\n",
    "            temp[\"duration\"] = tempDuration\n",
    "            durationList.append(tempDuration)\n",
    "            temp[\"realID\"] = realID[i]\n",
    "            sail = xr.concat([sail, temp], dim=\"time\")\n",
    "            temp.close()\n",
    "\n",
    "    # reformat dates\n",
    "    sail['date'] = mdates.date2num(sail['time'].dt.date)\n",
    "\n",
    "    # ask what variable should be plotted\n",
    "    return(sail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3635e-b73e-415d-8ded-593216c16c1d",
   "metadata": {},
   "source": [
    "## westcoast Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2645b38-7f78-46f9-938b-9ad99743ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: William Gilmore\n",
    "#Isolates data on the westcoast\n",
    "def westcoast(upperLat, lowerLat):\n",
    "    \n",
    "    #upperLat: Upper acceptable latitude\n",
    "    #lowerLat: Lower acceptable latitude\n",
    "    # -function will discard all data not between upperLat and lowerLat\n",
    "    \n",
    "    # Runs Pauls function to gather all saildrone data into 1 dataset\n",
    "    ds = Compile_Datasets(\"all\")\n",
    "    \n",
    "    \n",
    "    #Removes data that is not within 300 km of shore\n",
    "    ds = ds.where(ds.dist_land <= 300)\n",
    "    \n",
    "    #Removes SF bay data\n",
    "    ds = ds.where(~(((ds.lon > -122.5938) & (ds.lat > 37.72783)) & ((ds.lon < -122.2506620424831) & (ds.lat < 38.094658646550556))) | ~(((ds.lon > -122.38678630116495) & (ds.lat > 37.430464705762226)) & ((ds.lon < -121.99799777841487) & (ds.lat < 37.81408437558721))))\n",
    "    \n",
    "    #Removes Data not between upperLat and lowerLat\n",
    "    ds = ds.where((ds.lat > lowerLat) & (ds.lat < upperLat))\n",
    "     \n",
    "\n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfbcdb-eaf5-4c02-8261-67046d65fe9d",
   "metadata": {},
   "source": [
    "## Sample Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66712eab-9881-450f-a1c3-c0794e8610c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds = westcoast(50, 20) # All westcoast voyages are within this range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e4c76-bedc-4611-bc41-c1cd5d8bb1f1",
   "metadata": {},
   "source": [
    "## Test Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e721ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of ticks for the x axis\n",
    "default_x_ticks = range(0,len(ds['time']),divmod(len(ds['time']), 10)[0]) #selects out 10 evenly spaced dates from the data\n",
    "\n",
    "#define latitude and longitude boundaries\n",
    "latr = [27, 52] \n",
    "lonr = [-115, -130] \n",
    "\n",
    "# Select a region of our data, giving it a margin\n",
    "margin = 0.5 \n",
    "region = np.array([[latr[0]-margin,latr[1]+margin],[lonr[0]+margin,lonr[1]-margin]]) \n",
    "\n",
    "#add state outlines\n",
    "states_provinces = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_1_states_provinces_lines',\n",
    "        scale='50m',\n",
    "        facecolor='none')\n",
    "\n",
    "# Create and set the figure context\n",
    "fig = plt.figure(figsize=(16,10), dpi = 72) \n",
    "ax = plt.axes(projection=ccrs.PlateCarree()) \n",
    "ax.coastlines(resolution='10m',linewidth=1,color='black') \n",
    "ax.add_feature(cfeature.LAND, color='grey', alpha=0.3)\n",
    "ax.add_feature(states_provinces, linewidth = 0.5)\n",
    "ax.add_feature(cfeature.BORDERS)\n",
    "ax.set_extent([region[1,0],region[1,1],region[0,0],region[0,1]],crs=ccrs.PlateCarree()) \n",
    "ax.set_xticks(np.round([*np.arange(region[1,1],region[1,0]+1,2)][::-1],0), crs=ccrs.PlateCarree()) \n",
    "ax.set_yticks(np.round([*np.arange(np.floor(region[0,0]),region[0,1]+1,1.5)],1), crs=ccrs.PlateCarree()) \n",
    "ax.xaxis.set_major_formatter(LongitudeFormatter(zero_direction_label=True))\n",
    "ax.yaxis.set_major_formatter(LatitudeFormatter())\n",
    "ax.gridlines(linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "# Plot track data, color by temperature\n",
    "loc = mdates.AutoDateLocator()\n",
    "sc = plt.scatter(x = ds['lon'], y = ds['lat'], c = ds['date'], cmap='jet')\n",
    "#plt.plot(ds['lon'], ds['lat'], ls = ':', c = 'navy', alpha = 0.4)\n",
    "clb = fig.colorbar(sc, ticks=np.linspace(min(ds['date']), max(ds['date']), 11))\n",
    "clb.ax.set_title('Date')\n",
    "clb.set_ticklabels(ds['time'].dt.date[default_x_ticks].values)\n",
    "plt.title('Sampling Track for Cruise', fontdict = {'fontsize' : 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95467a43-c7f8-4202-b0e3-cb1143ee0da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "users-fi_intern",
   "language": "python",
   "name": "conda-env-users-fi_intern-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
